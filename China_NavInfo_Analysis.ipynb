{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "China_NavInfo_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1h6WSjrw9vQJ7cTFnzdos923JpGDMVoFv",
      "authorship_tag": "ABX9TyOXKB/QXZhn8IyBhj4ClId9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jenna-Williams/Python-Class/blob/master/China_NavInfo_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhUfGaYduwNz"
      },
      "source": [
        "#China NavInfo and B-F Discount Data Analysis (F20 - F21)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Overview\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Currently, B-F data is limited regarding where products are being sold at the retail-level in China markets. To help bridge the gap between distributors and consumers, location data was purchased from a third party, NavInfo. \n",
        "\n",
        "This colab notebook utilizes multiple datasets to get a more accurate look at sales by channels, including:\n",
        "* NavInfo location data (i.e.  Province, City, Account Name, Channel)\n",
        "* B-F Discount Data for F20 and F21\n",
        "* Discount Reconciliation Data for F20 and F21\n",
        "\n",
        "Ultimately, we are interested in what additional information we can gain when combining the NavInfo data with our discount data. Key fields we use from our discount data include volume, discounts, and brand size.\n",
        "From the NavInfo dataset we focus on location data such as city and outlets (\"Account Name\") which can be linked to the customers.\n",
        "\n",
        "The key question we seek to answer in this analysis, is \"how do customer sales relate to entity and outlet locations across China?\"\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Methods\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Translation (Chinese to English)\n",
        "Key information is translated (from Chinese to English) for the NavInfo and B-F datasets using the Google Translate API. This is done using the Python module 'googletrans'. \n",
        "### Matching\n",
        "After the translation, this data is added back to the original dataframe. Then we combine all datasets into a new dataframe for further analysis.\n",
        "\n",
        "### Additional Info:\n",
        "* Key information from BF and NavInfo files is translated: Chinese → English via googletrans\n",
        "* Key fields translated / used (“NavInfo Data” tab of \"NavInfo Data.xlsx\" file):  \n",
        "    1.   Account Name (Customer Name)\n",
        "    2.   City\n",
        "    3.   Province\n",
        "    4.   District\n",
        "* Add translated columns back to original dataframe.\n",
        "* Channel and customer mapping:\n",
        " * Select [Account Name] from B-F Discount Data (F20-F21) df.\n",
        " * Match to [Account Name] in NavInfo df.\n",
        " * Compare Customber by Brand Size.\n",
        "* Create results tables (similar to pivot tables from \"NavInfo Data.xlsx\" file to show:\n",
        " * Overview of NavInfo Outlets (by Province and City]\n",
        " * Overview of Customer Distribution to Outlets.\n",
        " * Top/Bottom 10 Accounts (By Discounts)\n",
        " * Example: In Beijing, the top 12 customers accounted for over 50 percent of discounts.\n",
        " * Brand Pack Size Top/Bottom Accounts\n",
        " * Example: Brannd Size - nearly 80% of discounts were for JD 700ml in Beijing.\n",
        "* Brand Pack Size by Customer\n",
        "* Listing and Selling Status by Customer (E.g. what listing opportunities would there be with existing customers?)\n",
        "* In the future, what could we expect in specific sub-channels for listings? For example, might we expect 'core listing in KTVs' to perform going forward?\n",
        "---\n",
        "\n",
        "\n",
        "##Results\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW6_SrvD7Ieg",
        "outputId": "6190afc3-34d9-4c5f-933a-7fff8a5febc9"
      },
      "source": [
        "# Import Packages\n",
        "!pip install -q xlrd\n",
        "import xlrd\n",
        "import io\n",
        "import json\n",
        "\n",
        "# Import necessary packages for Data Analytics/Visualization\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import rpy2 # to use R in python env\n",
        "import datetime as dt\n",
        "\n",
        "# Install in-line ggplot package for visualization\n",
        "!pip install tslib\n",
        "!pip install ggplot\n",
        "#from ggplot import *\n",
        "\n",
        "# Import Google Translator API package\n",
        "!pip install googletrans==3.1.0a0\n",
        "import googletrans\n",
        "from googletrans import Translator, constants\n",
        "from pprint import pprint\n",
        "#!pip install git+https://github.com/BoseCorp/py-googletrans.git --upgrade\n",
        "#!pip install git+https://github.com/lushan88a/google_trans_new.git --upgrade\n",
        "#!pip install google_trans_new\n",
        "#from google_trans_new import google_translator\n",
        "\n",
        "import six\n",
        "from google.cloud import translate_v2 as translate\n",
        "\n",
        "!pip install translate\n",
        "import translate\n",
        "\n",
        "# Install / Import OCR libraries\n",
        "!pip install pytesseract Pillow\n",
        "!pip install opencv-python\n",
        "!pip install pdf2image\n",
        "!pip install PyPDF2\n",
        "\n",
        "import cv2\n",
        "from pdf2image import convert_from_path\n",
        "import PyPDF2\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tslib\n",
            "  Downloading tslib-1.8-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tslib) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tslib) (1.15.0)\n",
            "Installing collected packages: tslib\n",
            "Successfully installed tslib-1.8\n",
            "Collecting ggplot\n",
            "  Downloading ggplot-0.11.5-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 3.8 MB/s \n",
            "\u001b[?25hCollecting brewer2mpl\n",
            "  Downloading brewer2mpl-1.4.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.1.5)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.7/dist-packages (from ggplot) (0.10.0)\n",
            "Requirement already satisfied: patsy>=0.4 in /usr/local/lib/python3.7/dist-packages (from ggplot) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ggplot) (3.2.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from ggplot) (0.10.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ggplot) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ggplot) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ggplot) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ggplot) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ggplot) (2018.9)\n",
            "Installing collected packages: brewer2mpl, ggplot\n",
            "Successfully installed brewer2mpl-1.4.1 ggplot-0.11.5\n",
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.5.30)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting hstspreload\n",
            "  Downloading hstspreload-2021.10.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.5 MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16367 sha256=de79ef16b5626d743cc796792beb62c600a3116acd1cb5f97b4d226cd51c2168\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/be/fe/93a6a40ffe386e16089e44dad9018ebab9dc4cb9eb7eab65ae\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2021.10.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n",
            "Collecting translate\n",
            "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
            "Collecting libretranslatepy==2.1.1\n",
            "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from translate) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from translate) (4.2.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from translate) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->translate) (1.24.3)\n",
            "Installing collected packages: libretranslatepy, translate\n",
            "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.8.tar.gz (14 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14072 sha256=7147adc95acb934a8a7c12a811fc810e21f9b379674d211ce66cd0de757dfec5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/89/b9/3f11250225d0f90e5454fcc30fd1b7208db226850715aa9ace\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.8\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.16.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pdf2image) (7.1.2)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.16.0\n",
            "Collecting PyPDF2\n",
            "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 2.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61101 sha256=16e1f5c46a9ea888d42387c6202369397a177cc2181a87750d92995d4467cd01\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1a/24/648467ade3a77ed20f35cfd2badd32134e96dd25ca811e64b3\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epq-4J1IK16Y"
      },
      "source": [
        "##Additional Resources\n",
        "\n",
        "Google Translation API:\n",
        "* Official Google API Documentation: https://cloud.google.com/translate/docs\n",
        "* Python googletrans Documentation: https://github.com/ssut/py-googletrans\n",
        "\n",
        "\n",
        "Articles:\n",
        "* Translate Pandas df: https://towardsdatascience.com/translate-a-pandas-data-frame-using-googletrans-library-fb0aa7fca592\n",
        "* Googletrans: http://zetcode.com/python/googletrans/\n",
        "* Using Google Translator in Python: https://www.codeproject.com/Tips/1236705/How-to-Use-Google-Translator-in-Python\n",
        "* Translate Column: https://stackoverflow.com/questions/58350457/excel-sheet-translation-using-python\n",
        "* Pandas: https://medium.com/analytics-vidhya/translate-list-and-pandas-data-frame-using-googletrans-library-in-python-f28b8cb84f21\n",
        "* Read the docs: https://py-googletrans.readthedocs.io/en/latest/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG-gKS-dhu9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79fb86ad-dfef-4d67-ebc7-b78b507b3d62"
      },
      "source": [
        "# Check python version\n",
        "!python --version"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CkMXQx9_MvI"
      },
      "source": [
        "Mount Google Drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRdZHSDYf_1a",
        "outputId": "e063daee-adfb-47fb-a7a7-3f2062446c6e"
      },
      "source": [
        "# Mounting Google Drive locally\n",
        "# Mount MyDrive on runtime using authoriazation code.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rbkGnWS8_TD",
        "outputId": "96bfafb3-c6f3-42d6-f125-8c49c3634f3f"
      },
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive/China NavInfo Data\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'13 cities account list 20210331.xlsx'\n",
            "'BF Channel Definition - 20191213.gsheet'\n",
            "'Brown-Forman Scotch Products Distribution Agreement 百富门单一麦芽威士忌经销协议 [EXECUTION VERSION] Fully Signed NOA.pdf'\n",
            "'Discount Reconciliation Report for F21 Apr 20210515.xlsx'\n",
            "'Discounts F20.xlsx'\n",
            "'Discounts F21.xlsx'\n",
            "'NavInfo and F20 Discount Data.xlsx'\n",
            " NavInfo_Data_Translated.xlsx\n",
            " output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL4-ipI9gGKE"
      },
      "source": [
        "# Import NavInfo Raw data sheet from \"NavInfo and F20 Discount Data.xlsx\" Excel file\n",
        "df_nav = pd.read_excel('/content/drive/My Drive/China NavInfo Data/NavInfo and F20 Discount Data.xlsx', sheet_name = 'NavInfo Raw data')\n",
        "#df_nav.head()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByVDJtgah05B"
      },
      "source": [
        "# Describe Data\n",
        "#df_nav.describe()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mth_i7oh_FuT"
      },
      "source": [
        "#Google Translator API\n",
        "\n",
        "Get Supported Languages\n",
        "Translate Columns\n",
        "Translate Rows\n",
        "Join Multiple Datasets\n",
        "\n",
        "1.   Get Supported Languages\n",
        "2.   Detect Language\n",
        "3.   Translate Columns/Rows\n",
        "4.   Join Multiple Datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XezQIE_nwtyc",
        "outputId": "039ba0cf-19ac-4cad-d273-daee80ab748a"
      },
      "source": [
        "\"\"\"\n",
        "# Using Google translator API (googletrans package)\n",
        "# List supported lanugages\n",
        "\n",
        "from googletrans import LANGUAGES\n",
        "\n",
        "for lang in LANGUAGES:\n",
        "  print(f'{lang} - {LANGUAGES[lang]}')\n",
        "\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Using Google translator API (googletrans package)\\n# List supported lanugages\\n\\nfrom googletrans import LANGUAGES\\n\\nfor lang in LANGUAGES:\\n  print(f'{lang} - {LANGUAGES[lang]}')\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OVyBXKU1lPAN",
        "outputId": "a5ef85b9-79bc-4790-caee-79b71c76fba3"
      },
      "source": [
        "# Get supported languages and corresponding codes\n",
        "\n",
        "#pd.set_option('max_colwidth', 300)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "\n",
        "lang_df = pd.DataFrame.from_dict(googletrans.LANGUAGES, orient='index', columns = ['Language'])\n",
        "lang_df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>af</th>\n",
              "      <td>afrikaans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sq</th>\n",
              "      <td>albanian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>am</th>\n",
              "      <td>amharic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ar</th>\n",
              "      <td>arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hy</th>\n",
              "      <td>armenian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>az</th>\n",
              "      <td>azerbaijani</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eu</th>\n",
              "      <td>basque</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>be</th>\n",
              "      <td>belarusian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bn</th>\n",
              "      <td>bengali</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bs</th>\n",
              "      <td>bosnian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bg</th>\n",
              "      <td>bulgarian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ca</th>\n",
              "      <td>catalan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ceb</th>\n",
              "      <td>cebuano</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ny</th>\n",
              "      <td>chichewa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zh-cn</th>\n",
              "      <td>chinese (simplified)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zh-tw</th>\n",
              "      <td>chinese (traditional)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>co</th>\n",
              "      <td>corsican</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hr</th>\n",
              "      <td>croatian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cs</th>\n",
              "      <td>czech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>da</th>\n",
              "      <td>danish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nl</th>\n",
              "      <td>dutch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>english</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eo</th>\n",
              "      <td>esperanto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>estonian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tl</th>\n",
              "      <td>filipino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fi</th>\n",
              "      <td>finnish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fr</th>\n",
              "      <td>french</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fy</th>\n",
              "      <td>frisian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gl</th>\n",
              "      <td>galician</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ka</th>\n",
              "      <td>georgian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>de</th>\n",
              "      <td>german</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>el</th>\n",
              "      <td>greek</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gu</th>\n",
              "      <td>gujarati</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ht</th>\n",
              "      <td>haitian creole</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ha</th>\n",
              "      <td>hausa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>haw</th>\n",
              "      <td>hawaiian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iw</th>\n",
              "      <td>hebrew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>he</th>\n",
              "      <td>hebrew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hi</th>\n",
              "      <td>hindi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hmn</th>\n",
              "      <td>hmong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hu</th>\n",
              "      <td>hungarian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is</th>\n",
              "      <td>icelandic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ig</th>\n",
              "      <td>igbo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>indonesian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ga</th>\n",
              "      <td>irish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>it</th>\n",
              "      <td>italian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ja</th>\n",
              "      <td>japanese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jw</th>\n",
              "      <td>javanese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kn</th>\n",
              "      <td>kannada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kk</th>\n",
              "      <td>kazakh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>km</th>\n",
              "      <td>khmer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ko</th>\n",
              "      <td>korean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ku</th>\n",
              "      <td>kurdish (kurmanji)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ky</th>\n",
              "      <td>kyrgyz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lo</th>\n",
              "      <td>lao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>la</th>\n",
              "      <td>latin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lv</th>\n",
              "      <td>latvian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lt</th>\n",
              "      <td>lithuanian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lb</th>\n",
              "      <td>luxembourgish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mk</th>\n",
              "      <td>macedonian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mg</th>\n",
              "      <td>malagasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ms</th>\n",
              "      <td>malay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ml</th>\n",
              "      <td>malayalam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mt</th>\n",
              "      <td>maltese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mi</th>\n",
              "      <td>maori</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mr</th>\n",
              "      <td>marathi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mn</th>\n",
              "      <td>mongolian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>my</th>\n",
              "      <td>myanmar (burmese)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ne</th>\n",
              "      <td>nepali</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no</th>\n",
              "      <td>norwegian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>or</th>\n",
              "      <td>odia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ps</th>\n",
              "      <td>pashto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fa</th>\n",
              "      <td>persian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pl</th>\n",
              "      <td>polish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pt</th>\n",
              "      <td>portuguese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pa</th>\n",
              "      <td>punjabi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ro</th>\n",
              "      <td>romanian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ru</th>\n",
              "      <td>russian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sm</th>\n",
              "      <td>samoan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gd</th>\n",
              "      <td>scots gaelic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sr</th>\n",
              "      <td>serbian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>st</th>\n",
              "      <td>sesotho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sn</th>\n",
              "      <td>shona</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sd</th>\n",
              "      <td>sindhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>si</th>\n",
              "      <td>sinhala</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sk</th>\n",
              "      <td>slovak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sl</th>\n",
              "      <td>slovenian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>so</th>\n",
              "      <td>somali</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>es</th>\n",
              "      <td>spanish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>su</th>\n",
              "      <td>sundanese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sw</th>\n",
              "      <td>swahili</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sv</th>\n",
              "      <td>swedish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tg</th>\n",
              "      <td>tajik</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ta</th>\n",
              "      <td>tamil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>te</th>\n",
              "      <td>telugu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>th</th>\n",
              "      <td>thai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tr</th>\n",
              "      <td>turkish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>uk</th>\n",
              "      <td>ukrainian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ur</th>\n",
              "      <td>urdu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ug</th>\n",
              "      <td>uyghur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>uz</th>\n",
              "      <td>uzbek</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vi</th>\n",
              "      <td>vietnamese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cy</th>\n",
              "      <td>welsh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xh</th>\n",
              "      <td>xhosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yi</th>\n",
              "      <td>yiddish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yo</th>\n",
              "      <td>yoruba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zu</th>\n",
              "      <td>zulu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Language\n",
              "af                 afrikaans\n",
              "sq                  albanian\n",
              "am                   amharic\n",
              "ar                    arabic\n",
              "hy                  armenian\n",
              "az               azerbaijani\n",
              "eu                    basque\n",
              "be                belarusian\n",
              "bn                   bengali\n",
              "bs                   bosnian\n",
              "bg                 bulgarian\n",
              "ca                   catalan\n",
              "ceb                  cebuano\n",
              "ny                  chichewa\n",
              "zh-cn   chinese (simplified)\n",
              "zh-tw  chinese (traditional)\n",
              "co                  corsican\n",
              "hr                  croatian\n",
              "cs                     czech\n",
              "da                    danish\n",
              "nl                     dutch\n",
              "en                   english\n",
              "eo                 esperanto\n",
              "et                  estonian\n",
              "tl                  filipino\n",
              "fi                   finnish\n",
              "fr                    french\n",
              "fy                   frisian\n",
              "gl                  galician\n",
              "ka                  georgian\n",
              "de                    german\n",
              "el                     greek\n",
              "gu                  gujarati\n",
              "ht            haitian creole\n",
              "ha                     hausa\n",
              "haw                 hawaiian\n",
              "iw                    hebrew\n",
              "he                    hebrew\n",
              "hi                     hindi\n",
              "hmn                    hmong\n",
              "hu                 hungarian\n",
              "is                 icelandic\n",
              "ig                      igbo\n",
              "id                indonesian\n",
              "ga                     irish\n",
              "it                   italian\n",
              "ja                  japanese\n",
              "jw                  javanese\n",
              "kn                   kannada\n",
              "kk                    kazakh\n",
              "km                     khmer\n",
              "ko                    korean\n",
              "ku        kurdish (kurmanji)\n",
              "ky                    kyrgyz\n",
              "lo                       lao\n",
              "la                     latin\n",
              "lv                   latvian\n",
              "lt                lithuanian\n",
              "lb             luxembourgish\n",
              "mk                macedonian\n",
              "mg                  malagasy\n",
              "ms                     malay\n",
              "ml                 malayalam\n",
              "mt                   maltese\n",
              "mi                     maori\n",
              "mr                   marathi\n",
              "mn                 mongolian\n",
              "my         myanmar (burmese)\n",
              "ne                    nepali\n",
              "no                 norwegian\n",
              "or                      odia\n",
              "ps                    pashto\n",
              "fa                   persian\n",
              "pl                    polish\n",
              "pt                portuguese\n",
              "pa                   punjabi\n",
              "ro                  romanian\n",
              "ru                   russian\n",
              "sm                    samoan\n",
              "gd              scots gaelic\n",
              "sr                   serbian\n",
              "st                   sesotho\n",
              "sn                     shona\n",
              "sd                    sindhi\n",
              "si                   sinhala\n",
              "sk                    slovak\n",
              "sl                 slovenian\n",
              "so                    somali\n",
              "es                   spanish\n",
              "su                 sundanese\n",
              "sw                   swahili\n",
              "sv                   swedish\n",
              "tg                     tajik\n",
              "ta                     tamil\n",
              "te                    telugu\n",
              "th                      thai\n",
              "tr                   turkish\n",
              "uk                 ukrainian\n",
              "ur                      urdu\n",
              "ug                    uyghur\n",
              "uz                     uzbek\n",
              "vi                vietnamese\n",
              "cy                     welsh\n",
              "xh                     xhosa\n",
              "yi                   yiddish\n",
              "yo                    yoruba\n",
              "zu                      zulu"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJABFSwG1uZ4",
        "outputId": "ec28f681-21c0-47c4-ecac-b19f5638d85e"
      },
      "source": [
        "# Listing supported languages\n",
        "print(googletrans.LANGUAGES)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'af': 'afrikaans', 'sq': 'albanian', 'am': 'amharic', 'ar': 'arabic', 'hy': 'armenian', 'az': 'azerbaijani', 'eu': 'basque', 'be': 'belarusian', 'bn': 'bengali', 'bs': 'bosnian', 'bg': 'bulgarian', 'ca': 'catalan', 'ceb': 'cebuano', 'ny': 'chichewa', 'zh-cn': 'chinese (simplified)', 'zh-tw': 'chinese (traditional)', 'co': 'corsican', 'hr': 'croatian', 'cs': 'czech', 'da': 'danish', 'nl': 'dutch', 'en': 'english', 'eo': 'esperanto', 'et': 'estonian', 'tl': 'filipino', 'fi': 'finnish', 'fr': 'french', 'fy': 'frisian', 'gl': 'galician', 'ka': 'georgian', 'de': 'german', 'el': 'greek', 'gu': 'gujarati', 'ht': 'haitian creole', 'ha': 'hausa', 'haw': 'hawaiian', 'iw': 'hebrew', 'he': 'hebrew', 'hi': 'hindi', 'hmn': 'hmong', 'hu': 'hungarian', 'is': 'icelandic', 'ig': 'igbo', 'id': 'indonesian', 'ga': 'irish', 'it': 'italian', 'ja': 'japanese', 'jw': 'javanese', 'kn': 'kannada', 'kk': 'kazakh', 'km': 'khmer', 'ko': 'korean', 'ku': 'kurdish (kurmanji)', 'ky': 'kyrgyz', 'lo': 'lao', 'la': 'latin', 'lv': 'latvian', 'lt': 'lithuanian', 'lb': 'luxembourgish', 'mk': 'macedonian', 'mg': 'malagasy', 'ms': 'malay', 'ml': 'malayalam', 'mt': 'maltese', 'mi': 'maori', 'mr': 'marathi', 'mn': 'mongolian', 'my': 'myanmar (burmese)', 'ne': 'nepali', 'no': 'norwegian', 'or': 'odia', 'ps': 'pashto', 'fa': 'persian', 'pl': 'polish', 'pt': 'portuguese', 'pa': 'punjabi', 'ro': 'romanian', 'ru': 'russian', 'sm': 'samoan', 'gd': 'scots gaelic', 'sr': 'serbian', 'st': 'sesotho', 'sn': 'shona', 'sd': 'sindhi', 'si': 'sinhala', 'sk': 'slovak', 'sl': 'slovenian', 'so': 'somali', 'es': 'spanish', 'su': 'sundanese', 'sw': 'swahili', 'sv': 'swedish', 'tg': 'tajik', 'ta': 'tamil', 'te': 'telugu', 'th': 'thai', 'tr': 'turkish', 'uk': 'ukrainian', 'ur': 'urdu', 'ug': 'uyghur', 'uz': 'uzbek', 'vi': 'vietnamese', 'cy': 'welsh', 'xh': 'xhosa', 'yi': 'yiddish', 'yo': 'yoruba', 'zu': 'zulu'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Lx3QxfMOky9B",
        "outputId": "fcff5996-c893-44c1-bb48-db18ac4191b7"
      },
      "source": [
        "# Find code for english and chinese\n",
        "lang_df[lang_df.Language.isin([\n",
        "                               'english', \n",
        "                               'chinese (simplified)', \n",
        "                               'chinese (traditional)'\n",
        "                               ])]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>zh-cn</th>\n",
              "      <td>chinese (simplified)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zh-tw</th>\n",
              "      <td>chinese (traditional)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>english</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Language\n",
              "zh-cn   chinese (simplified)\n",
              "zh-tw  chinese (traditional)\n",
              "en                   english"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiUCUGAi_5ub"
      },
      "source": [
        "##Testing Translations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktRqK3f-ythM",
        "outputId": "fa45a9db-81cc-40f8-f2b6-f99ec97ed555"
      },
      "source": [
        "# testing \n",
        "translator = Translator()  \n",
        "translate_text = translator.translate('สวัสดีจีน',lang_tgt='en')  \n",
        "print(translate_text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated(src=th, dest=en, text=hello china, pronunciation=None, extra_data=\"{'translat...\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQuoaOqDknOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b194dfc9-f129-491e-beed-dc1205fd089e"
      },
      "source": [
        "# Test the program to detect language\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "detector = Translator()\n",
        "dec_lan = detector.detect('이 문장은 한글로 쓰여졌습니다.')\n",
        "\n",
        "print(dec_lan)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected(lang=ko, confidence=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHvGr10phsHL",
        "outputId": "029bcca5-0ec8-4879-f3a2-cadbab382d61"
      },
      "source": [
        "# Test - get source and destination langauge, and print\n",
        "trans = Translator()\n",
        "t = trans.translate(\n",
        "    '이 문장은 한글로 쓰여졌습니다.'\n",
        ")\n",
        "\n",
        "# See source language\n",
        "print(f'Source: {t.src}')\n",
        "# See destination lanugage\n",
        "print(f'Destination: {t.dest}')\n",
        "# See translated text\n",
        "print(f'{t.origin} -> {t.text}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: ko\n",
            "Destination: en\n",
            "이 문장은 한글로 쓰여졌습니다. -> This sentence is written in Korean.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj4KILdeZ4C9",
        "outputId": "4a6d9f98-e12b-40b6-8282-be6e5cd1a1b5"
      },
      "source": [
        "trans = Translator()\n",
        "#t = trans.translate(('縣',\t'城市',\t'省',\t'用戶名', '地址',\t'分类1',\t'分类2',\t\n",
        "#                     '分类3',\t'分类编码',\t'业态'), \n",
        "#                     src ='zh-CN', dest='en')\n",
        "t = trans.translate('縣\t城市\t省\t用戶名 地址\t分类1\t分类2\t分类3\t分类编码\t业态', src ='zh-CN', dest='en')\n",
        "print(f'Source: {t.src}')\n",
        "print(f'Destination: {t.dest}')\n",
        "print(f'{t.origin} -> {t.text}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: zh-CN\n",
            "Destination: en\n",
            "縣\t城市\t省\t用戶名 地址\t分类1\t分类2\t分类3\t分类编码\t业态 -> County City Province User Name Address Category 1 Category 2 Category 3 Category Code Business Type\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHkPXrrAoPlM",
        "outputId": "0ebba598-280d-4b23-ac73-bc8e0abfe12b"
      },
      "source": [
        "# Test possible mistakes\n",
        "trans = Translator()\n",
        "t = trans.translate(\n",
        "    '이 문장은 한글로 쓰여졌습니다.', src='ko', dest ='en'\n",
        ")\n",
        "\n",
        "# See source language\n",
        "print(f'Source: {t.src}')\n",
        "# See destination lanugage\n",
        "print(f'Destination: {t.dest}')\n",
        "# See translated text\n",
        "print(f'{t.origin} -> {t.text}')\n",
        "\n",
        "# Check translation - dictionary for possible mistakes and possible translations\n",
        "pm = t.extra_data['possible-mistakes']\n",
        "pt = t.extra_data['possible-translations']\n",
        "print(f'Possible Mistakes: {pm}')\n",
        "print(f'Possible Translations: {pt}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: ko\n",
            "Destination: en\n",
            "이 문장은 한글로 쓰여졌습니다. -> This sentence is written in Korean.\n",
            "Possible Mistakes: None\n",
            "Possible Translations: [['이 문장은 한글로 쓰여졌습니다.', None, [['This sentence is written in Korean.', 0, True, False, [3]], ['This sentence is written in Hangul.', 0, True, False, [0]]], [[0, 17]], '이 문장은 한글로 쓰여졌습니다.', 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQz1epLWnymT",
        "outputId": "f0f44706-d99c-4193-c7d0-75324149e9fa"
      },
      "source": [
        "# Test - get source and destination lanugage, and print\n",
        "trans = Translator()\n",
        "t = trans.translate('用戶名')\n",
        "\n",
        "# See source language\n",
        "print(f'Source: {t.src}')\n",
        "# See destination lanugage\n",
        "print(f'Destination: {t.dest}')\n",
        "# See translated text\n",
        "print(f'{t.origin} -> {t.text}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: zh-CN\n",
            "Destination: en\n",
            "用戶名 -> username\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H8PYMeaoTTf",
        "outputId": "49bb7f42-0c2c-4a91-dacf-39ac6c65e82c"
      },
      "source": [
        "# Test possible mistakes\n",
        "# Test - get source and destination lanugage, and print\n",
        "trans = Translator()\n",
        "t = trans.translate(('分类1, 用戶 名'), src ='zh-CN', dest = 'en')\n",
        "\n",
        "# See source language\n",
        "print(f'Source: {t.src}')\n",
        "# See destination lanugage\n",
        "print(f'Destination: {t.dest}')\n",
        "# See translated text\n",
        "print(f'{t.origin} -> {t.text}')\n",
        "\n",
        "# Check translation - dictionary for possible mistakes and possible translations\n",
        "pm = t.extra_data['possible-mistakes']\n",
        "pt = t.extra_data['possible-translations']\n",
        "print(f'Possible Mistakes: {pm}')\n",
        "print(f'Possible Translations: {pt}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: zh-CN\n",
            "Destination: en\n",
            "分类1, 用戶 名 -> Category 1, Username\n",
            "Possible Mistakes: None\n",
            "Possible Translations: [['分类1, 用戶 名', None, [['Category 1, Username', 0, True, False, [3]], ['Category 1, the user name', 0, True, False, [0]]], [[0, 9]], '分类1, 用戶 名', 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8e7BwkeRg8X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e97879fb-e691-48cf-d84b-862ca4444aee"
      },
      "source": [
        "\"\"\"\n",
        "# Translates text into the target language.\n",
        "# NOTE: Target must be an ISO 639-1 language code. See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
        "\n",
        "def translate_text(target, text):\n",
        "  translate_client = translate.Client()\n",
        "  \n",
        "  if isinstance(text, six.binary_type):\n",
        "    text = text.decode(\"utf-8\")\n",
        "\n",
        "    # Text can also be a sequence of strings, in which case this method\n",
        "    # will return a sequence of results for each text.\n",
        "    result = translate_client.translate(text, target_language=target)\n",
        "\n",
        "    print(u\"Text: {}\".format(result[\"input\"]))\n",
        "    print(u\"Translation: {}\".format(result[\"translatedText\"]))\n",
        "    print(u\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\n",
        "\"\"\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Translates text into the target language.\\n# NOTE: Target must be an ISO 639-1 language code. See https://g.co/cloud/translate/v2/translate-reference#supported_languages\\n\\ndef translate_text(target, text):\\n  translate_client = translate.Client()\\n  \\n  if isinstance(text, six.binary_type):\\n    text = text.decode(\"utf-8\")\\n\\n    # Text can also be a sequence of strings, in which case this method\\n    # will return a sequence of results for each text.\\n    result = translate_client.translate(text, target_language=target)\\n\\n    print(u\"Text: {}\".format(result[\"input\"]))\\n    print(u\"Translation: {}\".format(result[\"translatedText\"]))\\n    print(u\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0VwBW5nS5Ki",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b1958e86-d5ad-4c2b-e546-3af863389110"
      },
      "source": [
        "\"\"\"\n",
        "# Testing googletrans API\n",
        "# Translate word doc file and save result as doc (keeping same file format).\n",
        "\n",
        "#:param filename: word doc file\n",
        "#:param destination='zh-CN':\n",
        "#:param mix=True: if True, will have original language and target language into the same doc. paragraphs by paragraphs.\n",
        "\n",
        "def translate_doc(filename, destination='zh-CN', mix=True):\n",
        "  def tx(t): return Translator().translate(t, dest=destination).text\n",
        "  doc = Document(filename)\n",
        "  for p in doc.paragraphs:\n",
        "    txd = tx(p.text)\n",
        "    \n",
        "    p.text = p.text + ('\\n' + txd if mix else '')\n",
        "\n",
        "    for table in doc.tables:\n",
        "      for row in table.rows:\n",
        "        for cell in row.cells:\n",
        "          txd = tx(cell.text)\n",
        "          p.text = cell.text + ('\\n' + txd if mix else '')\n",
        "\n",
        "    f = filename.replace('.doc', destination.lower() + '.doc')\n",
        "    doc.save(f) \n",
        "\"\"\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Testing googletrans API\\n# Translate word doc file and save result as doc (keeping same file format).\\n\\n#:param filename: word doc file\\n#:param destination='zh-CN':\\n#:param mix=True: if True, will have original language and target language into the same doc. paragraphs by paragraphs.\\n\\ndef translate_doc(filename, destination='zh-CN', mix=True):\\n  def tx(t): return Translator().translate(t, dest=destination).text\\n  doc = Document(filename)\\n  for p in doc.paragraphs:\\n    txd = tx(p.text)\\n    \\n    p.text = p.text + ('\\n' + txd if mix else '')\\n\\n    for table in doc.tables:\\n      for row in table.rows:\\n        for cell in row.cells:\\n          txd = tx(cell.text)\\n          p.text = cell.text + ('\\n' + txd if mix else '')\\n\\n    f = filename.replace('.doc', destination.lower() + '.doc')\\n    doc.save(f) \\n\""
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "O5chZy7J4lT3",
        "outputId": "9185ccba-5d12-4e02-8e17-de851f1f3dfd"
      },
      "source": [
        "# Testing googletrans on one column 'Tier 1 WS: Account Name' in 'testing' sheet of \"Discounts F20.xlsx\"\n",
        "df = pd.read_excel('/content/drive/MyDrive/China NavInfo Data/Discounts F20.xlsx', sheet_name=\"testing\")\n",
        "df.tail(10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tier 1 WS: Account Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>中山市汇广商贸有限公司</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>中山市汇广商贸有限公司</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>中山市汇广商贸有限公司</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>中山市汇广商贸有限公司</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>中山市汇广商贸有限公司</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>中山市汇广商贸有限公司</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>中山市汇广商贸有限公司</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>中山市汇广商贸有限公司</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>中山市汇广商贸有限公司</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>中山市汇广商贸有限公司</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Tier 1 WS: Account Name\n",
              "557             中山市汇广商贸有限公司\n",
              "558             中山市汇广商贸有限公司\n",
              "559             中山市汇广商贸有限公司\n",
              "560             中山市汇广商贸有限公司\n",
              "561             中山市汇广商贸有限公司\n",
              "562             中山市汇广商贸有限公司\n",
              "563             中山市汇广商贸有限公司\n",
              "564             中山市汇广商贸有限公司\n",
              "565             中山市汇广商贸有限公司\n",
              "566             中山市汇广商贸有限公司"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akuZWE4-5_p1",
        "outputId": "6753e3fe-f917-4926-ab52-97afeadc6f11"
      },
      "source": [
        "# Building translator function and translating test df\n",
        "translator = Translator()\n",
        "translations = {}\n",
        "for column in df.columns:\n",
        "\n",
        "  # Unique elements of column\n",
        "\n",
        "  unique_elements = df[column].unique()\n",
        "  for element in unique_elements:\n",
        "\n",
        "    # Adding all translations to a dictionary (translations)\n",
        "\n",
        "    translations[element] = translator.translate(element).text\n",
        "\n",
        "translations"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'中山市汇广商贸有限公司': 'Zhongshan Huiguang Trading Co., Ltd.'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SnVcI1r26Xsd",
        "outputId": "241ebcab-39ce-4619-e5c9-be93ad070e33"
      },
      "source": [
        "# Replacing translated words to orginal data frame\n",
        "df.replace(translations, inplace = True)\n",
        "df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tier 1 WS: Account Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zhongshan Huiguang Trading Co., Ltd.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Zhongshan Huiguang Trading Co., Ltd.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Zhongshan Huiguang Trading Co., Ltd.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Zhongshan Huiguang Trading Co., Ltd.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Zhongshan Huiguang Trading Co., Ltd.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Tier 1 WS: Account Name\n",
              "0  Zhongshan Huiguang Trading Co., Ltd.\n",
              "1  Zhongshan Huiguang Trading Co., Ltd.\n",
              "2  Zhongshan Huiguang Trading Co., Ltd.\n",
              "3  Zhongshan Huiguang Trading Co., Ltd.\n",
              "4  Zhongshan Huiguang Trading Co., Ltd."
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9fSulYtV920"
      },
      "source": [
        "# NavInfo Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "3lUGHzLQ6rOp",
        "outputId": "1a8fbb75-36b0-45f7-b044-6c586c03b893"
      },
      "source": [
        "df_navinfo = pd.read_excel('/content/drive/MyDrive/China NavInfo Data/NavInfo Data_CN.xlsx', sheet_name=\"NavInfo Data_cn\")\n",
        "df_navinfo.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-871f022aec26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_navinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/China NavInfo Data/NavInfo Data_CN.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NavInfo Data_cn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_navinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/China NavInfo Data/NavInfo Data_CN.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiS5GBJAM1XU"
      },
      "source": [
        "translator = Translator()\n",
        "df_navinfo = pd.read_excel('/content/drive/MyDrive/China NavInfo Data/NavInfo Data_CN.xlsx', sheet_name=\"NavInfo Data_cn\")\n",
        "#df_navinfo['County', 'City', 'Province', 'Account Name', 'Address', 'Category 1', 'Category 2', 'Category 3', 'Channel'] = df_navinfo['縣',\t'城市',\t'省',\t'用戶名',\t'地址',\t'分类1',\t'分类2', '分类3',\t'业态'].apply(translator.translate, src='zh-cn', dest='en').apply(getattr, args=('text',))\n",
        "df_navinfo['County'] = df_navinfo['縣'].apply(translator.translate, src='zh-cn', dest='en').apply(getattr, args=('text',))\n",
        "df_navinfo.head()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmvof1_166AN"
      },
      "source": [
        "### NavInfo Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4kwdCpY5gHY"
      },
      "source": [
        "\"\"\"\n",
        "# Read in full NavInfo data\n",
        "df_navinfo_full = pd.read_excel('/content/drive/MyDrive/China NavInfo Data/NavInfo Data.xlsx', sheet_name=\"NavInfo Data\")\n",
        "df_navinfo_full.head()\n",
        "# Drop navinfo df columns (in English)\n",
        "df_navinfo_full.drop(['poi_id', 'Longitude', 'Latitude', 'County Code', 'City Code', \n",
        "               'Province Code', 'Brand', 'City EN',\t'County EN', 'Province EN', \n",
        "               'Account Name EN', 'Category1 EN',\t'Category2 EN', 'Category3 EN',\t\n",
        "               'On / Off-Trade', 'Channel',\t'Sub-Channel', 'Banner'], axis=1, inplace=True)\n",
        "df_navinfo_full.head()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53I0T33DZmHq"
      },
      "source": [
        "# Articles for translating pandas df using googletrans:\n",
        "# https://towardsdatascience.com/translate-a-pandas-data-frame-using-googletrans-library-fb0aa7fca592\n",
        "# https://pypi.org/project/googletrans/\n",
        "# http://zetcode.com/python/googletrans/\n",
        "# https://www.codeproject.com/Tips/1236705/How-to-Use-Google-Translator-in-Python\n",
        "\n",
        "# Read in NavInfo data in Chinese (using the \"NavInfo Data_cn\" sheet from \"NavInfo Data_CN.xlsx\" file)\n",
        "df_navinfo_cn = pd.read_excel('/content/drive/MyDrive/China NavInfo Data/NavInfo Data_CN.xlsx', sheet_name='NavInfo Data_cn')\n",
        "df_navinfo_cn.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z48QjFnGFiGm"
      },
      "source": [
        "# Make a copy of the dataframe\n",
        "df_navinfo_en = df_navinfo_cn.copy()\n",
        "\n",
        "# Translate column names using rename function\n",
        "df_navinfo_en.rename(columns=lambda x: translator.translate(x).text, inplace=True)\n",
        "\n",
        "# Translated column names\n",
        "df_navinfo_en.columns\n",
        "\n",
        "#df_navinfo['County', 'City', 'Province', 'User Name', 'Address', 'Category 1', 'Category 2', 'Category 3', 'Category Code', 'Business Type'] = df_navinfo['縣',\t'城市',\t'省',\t'用戶名', '地址',\t'分类1',\t'分类2',\t'分类3',\t'分类编码',\t'业态].apply(translator.translate, src='zh-cn', dest='en').apply(getattr, args=('text',))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZf2WsFVFpoz"
      },
      "source": [
        "# Translate rows\n",
        "#translator = Translator()\n",
        "translations = {}\n",
        "for column in df_navinfo_en.columns:\n",
        "  # unique elements of column\n",
        "  unique_elements = df_navinfo_en[column].unique()\n",
        "  for element in unique_elements:\n",
        "    # add translation to dictionary\n",
        "    translations[element] = translator.translate(element).text\n",
        "\n",
        "#print(translations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD1fBcsCHAo2"
      },
      "source": [
        "\"\"\"\n",
        "# Check translations and formatting, then modify column names\n",
        "translations['city'] = 'City'\n",
        "translations['username'] = 'Account Name'\n",
        "translations['address'] = 'Address'\n",
        "translations['Format'] = 'Channel'\n",
        "\n",
        "print(translations)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxOkUaEuIKhi"
      },
      "source": [
        "# Replace in the dataframe\n",
        "df_navinfo_en.replace(translations, inplace=True)\n",
        "# Check modifications\n",
        "df_navinfo_en.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vuh595bIaSP"
      },
      "source": [
        "### Additional Steps:\n",
        "Key information from BF and NavInfo files is translated:\n",
        "Chinese → English via DeepL (to overcome XLS dyslexia)\n",
        "Key fields translated / used:\n",
        "Account Name (Customer Name) -- from “NavInfo Raw data” tab  \n",
        "City\n",
        "Province\n",
        "District\n",
        "\n",
        "1.   Repeat same steps to translate  B-F Discount Data (F20 and F21) from Chinese to English.\n",
        "2.   Add translated columns back to original dataframes.\n",
        "3.   Combine Discount Data (F20 and F21) into new dataframe.\n",
        "4.   Match Account Name from Discount Data to NavInfo Data. \n",
        "\n",
        "\n",
        "\n",
        "You will find the translated columns added on the right side of each raw data table. \n",
        "(--> the full data is then pulled into a Pivot each for easier manipulation)\n",
        "Rough (sub-) channel and customer mapping done to align both perspectives as much as possible \n",
        "(see hidden tabs with ´mapping´ in them).\n",
        "Manual: Select [customer EN name] from BF discount data and type into [Account name EN] in NavInfo Pivot to find match or proxy matches.\n",
        "Manual: Copy / Paste 3. onto Customer tab\n",
        "Manual: Copy/ Paste Customer by Brand Size info from BF Discount Pivot on same (4.) tab.\n",
        "I was lucky enough to have Customer examples where the name of the Customer mostly matched the banner name seen be the consumer and shopper as well. \n",
        "Where that is not the case (like Noah´s I believe), some more know how would be required to perform 3-5. If we had a mapping table of that, then 3-5 could be done a bit less manual, too I believe.\n",
        "\n",
        "Additional Info:\n",
        "Some simple overview tabs are added in blue\n",
        "Overview of NavInfo OUTLETS by province and city procured.\n",
        "As Customer <> Outlets, it becomes obvious that we need to figure out the Outlets in a customer to put it into perspective of the total.\n",
        "\n",
        "Customer overview\n",
        "Some ´fun facts´ shown - like that the top 12 Customers account for 51% of the investments into discounts.\n",
        " \n",
        "Brand Pack Size overview\n",
        "More fun facts - like that 78% of the discounts relate to JD 700ml.\n",
        "\n",
        "Brand Pack Size by Customer\n",
        "How is the listing and selling status by Customer? E.g. what listing opportunities would there be with existing customers etc.\n",
        "(there is a hidden tab that shows the channels the customers belong to)\n",
        "Naturally, if applying some Picture of Success for what we would expect in specific sub-channels (for instance ´core listing in KTV, convenience etc. ´) could immediately move from today (here: F20) to tomorrow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64xskLeb7L4I"
      },
      "source": [
        "###NavInfo Data Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pEHSjYA_y3u"
      },
      "source": [
        "# NavInfo Data - Translation\n",
        "# Make copy of NavInfo dataframe\n",
        "df_navinfo_en = df_navinfo.copy()\n",
        "\n",
        "# Translate column names using rename function\n",
        "df_navinfo_en.rename(columns=lambda x: translator.translate(x).text, inplace = True)\n",
        "\n",
        "# Translated column names\n",
        "df_navinfo_en.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3TqarRX8snU"
      },
      "source": [
        "translations = {}\n",
        "for column in df_navinfo_en.columns:\n",
        "\n",
        "  # Unique elements of the columnn\n",
        "  unique_elements = df_navinfo_en[column].unique()\n",
        "  for element in unique_elements:\n",
        "\n",
        "    # Adding all translations to dictionary (translations)\n",
        "    translations[element] = translator.translate(element).text\n",
        "\n",
        "print(translations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEEhLVws5cIX"
      },
      "source": [
        "# Replacing translated words from translations dictionary to original dataframe\n",
        "df_navinfo_en.replace(translations, inplace = True)\n",
        "df_navinfo_en.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrGbX7CmBuMU"
      },
      "source": [
        "###NavInfo Translated Data Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX4yTX5iNxF-"
      },
      "source": [
        "# Export df to excel\n",
        "df_navinfo_en.to_excel('/content/drive/MyDrive/China NavInfo Data/output/navinfo-en.xlsx', sheet_name=\"navinfo-en\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2kRJ5FBV2Gw"
      },
      "source": [
        "#Brown-Forman F20 Discount Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqXkaQ-F6y76"
      },
      "source": [
        "# Import F-F Discount Data for F20 from 'Discounts F20.xlsx' Excel file from MyDrive\n",
        "df_bf_f20_discount = pd.read_excel('/content/drive/My Drive/China NavInfo Data/Discounts F20.xlsx', sheet_name = 'Data_F20')\n",
        "df_bf_f20_discount.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wq8RuuA-3wC"
      },
      "source": [
        "### F20 Discount Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr7yyEDQVyPD"
      },
      "source": [
        "# F20 Discount Data - Translation\n",
        "# Drop f20 columns (in English)\n",
        "df_bf_f20_discount.drop(['Account: Region',\t'Sales Org',\t'Region',\t'Approval Status', 'Approval Status2',\t\n",
        "                         'Actual Date',\t'Plan Date',\t'Depletion month', 'Fiscal Year', 'Year+Month',\t\n",
        "                         'Channel',\t'Group',\t'Subgroup', 'Province', 'City',\t'Brand',\t'Brand(PT)',\t\n",
        "                         'Brand (Accounting)', 'Brand Code',\t'Product Name: Product Name',\t'Act Qty',\t\n",
        "                         'Actual Discount','Act Payment',\t'Account: Account Owner: Alias', 'Promotion Start Date',\t\n",
        "                         'Promotion End Date',\t'Remarks',\t'T1',\t'Monthly Bottle Qty', 'On Invoice Discount',\t\n",
        "                         'On Invoice Discount Amount', 'Payment','BF Actual Payment',\t'Multiplier (9Lcs)',\t'Act Qty (9Lcs)',\t\n",
        "                         'Multiplier (Btl)',\t'Act Qty (Btl 700ml)',\t'Comments\t', 'Remark'], axis=1, inplace=True)\n",
        "df_bf_f20_discount.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxsn1613_K6W"
      },
      "source": [
        "###F20 Data Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLxbEaECVqLn"
      },
      "source": [
        "# Make copy of F20 dataframe\n",
        "df_bf_f20_discount_en = df_bf_f20_discount.copy()\n",
        "\n",
        "# Translate column names using rename function\n",
        "df_bf_f20_discount_en.rename(columns=lambda x: translator.translate(x).text, inplace = True)\n",
        "\n",
        "# Translated column names\n",
        "df_bf_f20_discount_en.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BuL41vJ_c5y"
      },
      "source": [
        "# Translate to English, and add columns back into the DataFrame\n",
        "# f20 dictionary\n",
        "translations = {}\n",
        "for column in df_bf_f20_discount_en.columns:\n",
        "  # Unique elements of column\n",
        "  unique_elements = df_bf_f20_discount_en[column].unique()\n",
        "  for element in unique_elements:\n",
        "    # Add translation to dictionary\n",
        "    translations[element] = translator.translate(element).text\n",
        "\n",
        "print(translations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z43wKc81_oWj"
      },
      "source": [
        "# Replacing translated words from translations dictionary to original dataframe\n",
        "df_bf_f20_discount_en.replace.replace(translations, inplace = True)\n",
        "df_bf_f20_discount_en.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e5WUWNhBk3C"
      },
      "source": [
        "###F20 Translated Data Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1daA4sBSVf-2"
      },
      "source": [
        "# Export translated f20 df to excel\n",
        "df_bf_f20_discount_en.to_excel('/content/drive/MyDrive/China NavInfo Data/output/f20-en.xlsx', sheet_name=\"f20-en\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEUno_a1WEBa"
      },
      "source": [
        "#Brown-Forman F21 Discount Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfLCAkMm6y-b"
      },
      "source": [
        "# Import B-F Discount Data for F21 from 'Discounts F21.xlsx' Excel file from MyDrive\n",
        "df_bf_f21_discount = pd.read_excel('/content/drive/My Drive/China NavInfo Data/Discounts F21.xlsx', sheet_name = 'Data_F21')\n",
        "df_bf_f21_discount.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xoIg7fBApGl"
      },
      "source": [
        "###F21 Discount Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMgFMNIf6yPg"
      },
      "source": [
        "# Drop columns f21 df (in English)\n",
        "df_bf_f21_discount.drop(['Account: Region',\t'Depletion month',\t'Fiscal Year',\t'Year+Month', 'Channel',\n",
        "                         'Group', 'Subgroup', 'Province', 'City',\t'Brand',\t'Brand(PT)', 'Brand (Accounting)', \n",
        "                         'Brand Code', 'JDTW', 'Brand Code', 'Product Name: Product Name',\t'Act Qty',\t\n",
        "                         'Actual Discount',\t'Act Payment',\t'Account: Account Owner: Alias',\t'Promotion Start Date',\n",
        "                         'Promotion End Date', 'Remarks',\t'T1',\t'Monthly Bottle Qty', 'On Invoice Discount',\t\n",
        "                         'On Invoice Discount Amount', 'Payment','BF Actual Payment',\t'Multiplier (9Lcs)',\t\n",
        "                         'Act Qty (9Lcs)', 'Multiplier (Btl)',\t'Act Qty (Btl 700ml)',\t'Comments\t', 'Remark'], axis=1, inplace=True)\n",
        "df_bf_f21_discount.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJOncQxnBADQ"
      },
      "source": [
        "###F21 Data Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBOXJze56rmO"
      },
      "source": [
        "# F21 Discount Data - Translation\n",
        "# Make copy of F21 dataframe\n",
        "df_bf_f21_discount_en = df_bf_f20_discount.copy()\n",
        "\n",
        "# Translate column names using rename function\n",
        "df_bf_f21_discount_en.rename(columns=lambda x: translator.translate(x).text, inplace = True)\n",
        "\n",
        "# Translated column names\n",
        "df_bf_f21_discount_en.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spqvTTuIWQMt"
      },
      "source": [
        "# f21 dictionary\n",
        "translations = {}\n",
        "for column in df_bf_f21_discount_en.columns:\n",
        "  # Unique elements of column\n",
        "  unique_elements = df_bf_f21_discount_en[column].unique()\n",
        "  for element in unique_elements:\n",
        "    # Add translation to dictionary\n",
        "    translations[element] = translator.translate(element).text\n",
        "\n",
        "print(translations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4gFM8nCWSgf"
      },
      "source": [
        "# Modify dataframe by using replace funciton, with dictionary as input\n",
        "# Modify all terms of df_bf_f21_discount\n",
        "df_bf_f21_discount_en.replace(translations, inplace=True)\n",
        "\n",
        "# Check translations\n",
        "df_bf_f21_discount_en.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpu1qM-0Bb9a"
      },
      "source": [
        "###F21 Translated Data Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K42MVu9eWWnT"
      },
      "source": [
        "# Export df to excel\n",
        "df_bf_f21_discount_en.to_excel('content/drive/MyDrive/China NavInfo Data/output/f21-en.xlsx', sheet_name='f21-en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idXuBvtllzjj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM5bFMr2a2YF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erDBb_J9ayZm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZQsLF1e8tyb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6vM5LTEB-wm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9bR3qei4Tzb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk8zVhzv88n2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaJMU8wmqJLw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3VKozuN_ANi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AALR__INqKoL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE4YOFI9uwZC"
      },
      "source": [
        "# Using Google Translate API\n",
        "def translate_text(target, text):\n",
        "    \"\"\"Translates text into the target language.\n",
        "\n",
        "    Target must be an ISO 639-1 language code.\n",
        "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
        "    \"\"\"\n",
        "    import six\n",
        "    from google.cloud import translate_v2 as translate\n",
        "\n",
        "    translate_client = translate.Client()\n",
        "\n",
        "    if isinstance(text, six.binary_type):\n",
        "        text = text.decode(\"utf-8\")\n",
        "\n",
        "    # Text can also be a sequence of strings, in which case this method\n",
        "    # will return a sequence of results for each text.\n",
        "    result = translate_client.translate(text, target_language=target)\n",
        "\n",
        "    print(u\"Text: {}\".format(result[\"input\"]))\n",
        "    print(u\"Translation: {}\".format(result[\"translatedText\"]))\n",
        "    print(u\"Detected source language: {}\".format(result[\"detectedSourceLanguage\"]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaQMj2T_wR3b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8Apot6-xXux"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiCKx9tHX8I0"
      },
      "source": [
        "\n",
        "text1 = '''\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "京东商城\n",
        "英伦纯K量贩KTV\n",
        "天猫超市-朗家园供货\n",
        "天猫超市-朗家园供货\n",
        "天猫超市-朗家园供货\n",
        "天猫超市-朗家园供货\n",
        "'''\n",
        "\n",
        "text2 = '''\n",
        "Vysoké Tatry sú najvyššie pohorie na Slovensku a v Poľsku a sú zároveň jediným \n",
        "horstvom v týchto štátoch s alpským charakterom. \n",
        "'''\n",
        "\n",
        "translator = Translator()\n",
        "\n",
        "dt1 = translator.detect(text1)\n",
        "print(dt1)\n",
        "\n",
        "dt2 = translator.detect(text2)\n",
        "print(dt2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGUcDLlwyDOA"
      },
      "source": [
        "# Using rpy2\n",
        "# Google API KEY:::\n",
        "#api.key <- ''\n",
        "\n",
        "# Read in 'database' tab from F21 Discounts\n",
        "#df <- read_csv(\"Discounts_F21_data.csv\",\n",
        "#              locale = locals())\n",
        "\n",
        "# Convert Headers:\n",
        "#names(df) <- make.names(names(df))\n",
        "\n",
        "# Translate\n",
        "#test <- translate(content.vec = dfsTier.1.ws.Account.Name,\n",
        "#                  google.apikey\n",
        "#                  = my.api.key,\n",
        "#                  sourrce.lang = 'en',\n",
        "#                  target.lang ='de')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM1EHTZwiBOb"
      },
      "source": [
        "# Upload NavInfo and F20 Discount Data.xlsx file locally\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d4yqS5UZHlD"
      },
      "source": [
        "###Optical Character Recognition (OCR)\n",
        "B-F Distribution Agreement \n",
        "* Reading contents of pdf \n",
        "* Using OCR / Python libraries:\n",
        "  * pytesseract, pdf2image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jjfM-EzsCMS"
      },
      "source": [
        "try:\n",
        "  from PIL import Image\n",
        "except ImportError:\n",
        "  import Image\n",
        "import pytesseract\n",
        "\n",
        "def ocr_core(filename):\n",
        "  \"\"\"\n",
        "  This function handles core OCR image processing.\n",
        "  \"\"\"\n",
        "  text = pytesseract.image_to_string(Image.open(filename))\n",
        "  return text\n",
        "\n",
        "print(ocr_core('/content/drive/MyDrive/China NavInfo Data/B-F Distribution Agreement.pdf'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw2y4s9MK3i8"
      },
      "source": [
        "# importing required modules\n",
        "import PyPDF2\n",
        "\t\n",
        "# creating a pdf file object\n",
        "pdfFileObj = open('/content/drive/MyDrive/China NavInfo Data/Brown-Forman Scotch Products Distribution Agreement 百富门单一麦芽威士忌经销协议 [EXECUTION VERSION] Fully Signed NOA.pdf', 'rb')\n",
        "\t\n",
        "# creating a pdf reader object\n",
        "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
        "\t\n",
        "# printing number of pages in pdf file\n",
        "print(pdfReader.numPages)\n",
        "\t\n",
        "# creating a page object\n",
        "pageObj = pdfReader.getPage(0)\n",
        "\t\n",
        "# extracting text from page\n",
        "print(pageObj.extractText())\n",
        "\t\n",
        "# closing the pdf file object\n",
        "pdfFileObj.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzdT9vXhfxUG"
      },
      "source": [
        "#3 When finished\n",
        "drive.flush_and_unmount()\n",
        "print('All changes made in this colab session should now be visible in Drive.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRTzOqN7sBjb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}